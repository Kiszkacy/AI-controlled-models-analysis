environment:
  observation_space_size: 5 # Dimensionality of the observation space, number of features in each state observation.
  observation_space_low: -100 # Lower bound for each dimension in the observation space.
  observation_space_high: 100 # Upper bound for each dimension in the observation space.
  action_space_range: 2  # Number of possible actions the agent can take in the environment
  action_space_low: -1 # Lower bound for each dimension in the action space.
  action_space_high: 1 # Upper bound for each dimension in the action space.
  number_of_agents: 25 # Number af agents in environment starting

training:
  is_resume: False  # Defines if it's a resume of training or not
  training_iterations: 2000  # Total number of training iterations (over a) to perform.
  training_checkpoint_frequency: 10 # Number of training steps how often Tuner is saved
  config_settings:
    number_of_workers: 2  # Number of parallel processes to use for training.
    number_of_env_per_worker: 1  # Number of training environments simulated by each worker process.
    training_batch_size: 4096 # 2048 # Total amount of environment steps taken during each training iteration
    use_gpu: True # Defines if gpu should be used
    algorithm: "PPO" # Algorithm used for training, works with PPO, DQN, SAC
    lr: 1e-4  # The learning rate, which determines how fast the model adjusts its weights during training.
    grad_clip: 0.5  # Gradient clipping to prevent exploding gradients, which can lead to instability during training
    gamma: 0.95  # The discount factor that controls how much future rewards are considered in the agentâ€™s decisions
    entropy_coeff: 0.01  # The entropy coefficient that balances exploration and exploitation
    clip_param: 0.1  # The clipping parameter used in PPO to limit changes to the policy within a specified range
    lstm_cell_size: 256  # Number of units (neurons) in lstm
    max_seq_len: 32  # The maximum sequence length that the LSTM can process at a time. It determines how many previous steps are considered when making a decision.
    fcnet_hiddens: [ 256, 256 ]  # A list specifying the number of units in the hidden layers of the fully connected neural network.

storage:
  name: "experiment_less_workers"  # Experiment name
  save_path: "C:\\Users\\sokol\\PycharmProjects\\AI-controlled-models-analysis\\core\\src\\models\\tuner"  # Dir where the model will be saved/restored from
  max_checkpoints: 5  # Num of checkpoints saved
  restore_iteration:  # If we want to restore model from "special" iteration we need to provide it here (needs to be in the saved iterations!),
  # by default empty/None restarts training from the latest checkpoint
